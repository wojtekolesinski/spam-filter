{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda4da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b7949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data, operation=\"train\"):\n",
    "    data = data.sample(frac=1, random_state=43)\n",
    "    train_last_index = int(data.shape[0] * 0.8)\n",
    "\n",
    "    vocab = set()\n",
    "    for row in data['SMS']:\n",
    "        vocab.update(row.split())\n",
    "    col_index = list(vocab)\n",
    "    col_index.sort()\n",
    "    \n",
    "    if operation == 'train':\n",
    "        data = data.iloc[0:train_last_index]\n",
    "    elif operation == 'test':\n",
    "        data = data.iloc[train_last_index:]\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    bag = pd.DataFrame(0, index=range(len(data)), columns=col_index)\n",
    "    for i, row in data['SMS'].iteritems():\n",
    "        for word in row.split():\n",
    "            if word in vocab:\n",
    "                bag.loc[i, word] += 1\n",
    "\n",
    "    return pd.concat([data, bag], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c46b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_csv(\"data/spam.csv\", encoding='iso-8859-1', header=0, usecols=[0, 1], dtype=str)\n",
    "df.columns = ['Target', 'SMS']\n",
    "en_sm_model = spacy.load(\"en_core_web_sm\")\n",
    "df['Target'] = df['Target'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99304ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "for i, row in df.iterrows():\n",
    "        text = row['SMS'].lower()\n",
    "        doc = en_sm_model(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if re.search(r\"[0-9]+\", token.lemma_):\n",
    "                new_text.append(\"aanumbers\")\n",
    "            else:\n",
    "                word = \"\".join([ch for ch in token.lemma_.lower() if ch not in punctuation])\n",
    "                if len(word) > 1 and word not in STOP_WORDS:\n",
    "                    new_text.append(word)\n",
    "\n",
    "        df['SMS'][i] = \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf034c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "train_bag_of_words = bag_of_words(df)\n",
    "test_bag_of_words = bag_of_words(df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0720420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting probabilities\n",
    "laplace_smoothing = 1\n",
    "\n",
    "spam_word_count = train_bag_of_words.loc[train_bag_of_words['Target'] == 'spam', 'aa':].aggregate(np.sum, axis=0)\n",
    "vocab_length = train_bag_of_words.iloc[:, 2:].shape[1]\n",
    "spam_length = train_bag_of_words.loc[train_bag_of_words['Target'] == 'spam'].SMS.str.split().apply(len).sum()\n",
    "spam_probability = (spam_word_count + laplace_smoothing) / (laplace_smoothing * vocab_length + spam_length)\n",
    "\n",
    "ham_word_count = train_bag_of_words.loc[train_bag_of_words['Target'] == 'ham', 'aa':].aggregate(np.sum, axis=0)\n",
    "ham_length = train_bag_of_words.loc[train_bag_of_words['Target'] == 'ham'].SMS.str.split().apply(len).sum()\n",
    "ham_probability = (ham_word_count + laplace_smoothing) / (laplace_smoothing * vocab_length + ham_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088915ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Spam Probability  Ham Probability\n",
      "aa                   0.000062         0.000062\n",
      "aah                  0.000062         0.000123\n",
      "aaniye               0.000062         0.000031\n",
      "aanumbers            0.148248         0.030110\n",
      "aaooooright          0.000062         0.000031\n",
      "...                       ...              ...\n",
      "amp                  0.000062         0.001970\n",
      "amplikater           0.000062         0.000062\n",
      "amrca                0.000062         0.000062\n",
      "amrita               0.000062         0.000031\n",
      "ams                  0.000062         0.000031\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "probabilities = pd.DataFrame(data={'Spam Probability':spam_probability, 'Ham Probability':ham_probability}, \n",
    "                             index=spam_probability.index)\n",
    "\n",
    "print(probabilities.iloc[:200])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db17097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_SPAM=0.2663527542973847, P_HAM=0.7336472457026153\n"
     ]
    }
   ],
   "source": [
    "P_SPAM = spam_length / (ham_length + spam_length)\n",
    "P_HAM = ham_length / (ham_length + spam_length)\n",
    "\n",
    "print(f'{P_SPAM=}, {P_HAM=}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25848b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_classifier(text, spam_prob, prob_table):\n",
    "        p_spam = spam_prob\n",
    "        p_ham = 1 - spam_prob\n",
    "    #     print(text)\n",
    "        for _word in text.split(' '):\n",
    "            try:\n",
    "                p_spam *= prob_table.loc[_word, 'Spam Probability']\n",
    "                p_ham *= prob_table.loc[_word, 'Ham Probability']\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if p_ham > p_spam:\n",
    "            return 'ham'\n",
    "        elif p_spam > p_ham:\n",
    "            return 'spam'\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd619383",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_prediction = test_bag_of_words.SMS.map(lambda x: spam_classifier(x, P_SPAM, probabilities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28207748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted Actual\n",
       "0         ham    ham\n",
       "1         ham    ham\n",
       "2        spam   spam\n",
       "3         ham    ham\n",
       "4         ham    ham\n",
       "..        ...    ...\n",
       "195      spam   spam\n",
       "196       ham    ham\n",
       "197       ham    ham\n",
       "198       ham    ham\n",
       "199       ham    ham\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Predicted': sms_prediction, 'Actual': test_bag_of_words['Target']}, index=sms_prediction.index)\n",
    "result.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e6eb792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN=143, FN=38, FP=5, TP=929\n"
     ]
    }
   ],
   "source": [
    "TP = result.loc[(result['Predicted'] == 'ham') & (result['Actual'] == 'ham')].shape[0]\n",
    "FP = result.loc[(result['Predicted'] == 'ham') & (result['Actual'] == 'spam')].shape[0]\n",
    "FN = result.loc[(result['Predicted'] == 'spam') & (result['Actual'] == 'ham')].shape[0]\n",
    "TN = result.loc[(result['Predicted'] == 'spam') & (result['Actual'] == 'spam')].shape[0]\n",
    "\n",
    "print(f'{TN=}, {FN=}, {FP=}, {TP=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248a4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Recall = TP / (TP + FN)\n",
    "Precision = TP / (TP + FP)\n",
    "F1 = 2 * Precision * Recall / (Precision + Recall)\n",
    "metrics = {'Accuracy': Accuracy, 'Recall': Recall, 'Precision': Precision, 'F1': F1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e46b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386f4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bag_of_words['TargetBinary'] = test_bag_of_words['Target'].apply(lambda x: 0 if x == 'ham' else 1)\n",
    "train_bag_of_words['TargetBinary'] = train_bag_of_words['Target'].apply(lambda x: 0 if x == 'ham' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d1f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X=train_bag_of_words.loc[:, 'aa':], y=train_bag_of_words['TargetBinary'])\n",
    "prediction = classifier.predict(X=test_bag_of_words.loc[:, 'aa':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec56d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9614349775784753, 'Recall': 0.9607032057911065, 'Precision': 0.9946466809421841, 'F1': 0.9773803261441346}\n",
      "{'Accuracy': 0.9856502242152466, 'Recall': 1.0, 'Precision': 0.9024390243902439, 'F1': 0.9487179487179488}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "classifier_metrics = {'Accuracy': accuracy_score(test_bag_of_words['TargetBinary'], prediction),\n",
    "                      'Recall': recall_score(test_bag_of_words['TargetBinary'], prediction),\n",
    "                      'Precision': precision_score(test_bag_of_words['TargetBinary'], prediction),\n",
    "                      'F1': f1_score(test_bag_of_words['TargetBinary'], prediction)}\n",
    "\n",
    "print(metrics)\n",
    "print(classifier_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
